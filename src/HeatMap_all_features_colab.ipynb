{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rachtibat/zennit-crp\n",
        "!pip install ./zennit-crp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SLoHkXnM9uF",
        "outputId": "617f350a-25c7-42db-e966-dc3da5f4cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'zennit-crp'...\n",
            "remote: Enumerating objects: 516, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 516 (delta 52), reused 47 (delta 41), pack-reused 431 (from 1)\u001b[K\n",
            "Receiving objects: 100% (516/516), 18.36 MiB | 6.32 MiB/s, done.\n",
            "Resolving deltas: 100% (285/285), done.\n",
            "Processing ./zennit-crp\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zennit<=0.4.6 (from zennit-crp==0.6.0)\n",
            "  Downloading zennit-0.4.6-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting torch<2.0.0,>=1.7.0 (from zennit-crp==0.6.0)\n",
            "  Downloading torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting numpy<=1.23.5 (from zennit-crp==0.6.0)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from zennit-crp==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from zennit-crp==0.6.0) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch<2.0.0,>=1.7.0->zennit-crp==0.6.0) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.0.0,>=1.7.0->zennit-crp==0.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.0.0,>=1.7.0->zennit-crp==0.6.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.0.0,>=1.7.0->zennit-crp==0.6.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.0.0,>=1.7.0->zennit-crp==0.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.7.0->zennit-crp==0.6.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.0.0,>=1.7.0->zennit-crp==0.6.0) (0.45.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from zennit<=0.4.6->zennit-crp==0.6.0) (8.1.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from zennit<=0.4.6->zennit-crp==0.6.0) (11.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from zennit<=0.4.6->zennit-crp==0.6.0) (0.20.1+cu124)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->zennit-crp==0.6.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->zennit-crp==0.6.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->zennit-crp==0.6.0) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->zennit-crp==0.6.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->zennit-crp==0.6.0) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->zennit-crp==0.6.0) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->zennit-crp==0.6.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->zennit-crp==0.6.0) (1.17.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from zennit<=0.4.6->zennit-crp==0.6.0)\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision->zennit<=0.4.6->zennit-crp==0.6.0) (2.32.3)\n",
            "  Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.16.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "  Downloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting zennit<=0.4.6 (from zennit-crp==0.6.0)\n",
            "  Downloading zennit-0.4.5-py3-none-any.whl.metadata (9.7 kB)\n",
            "  Downloading zennit-0.4.4-py3-none-any.whl.metadata (9.7 kB)\n",
            "  Downloading zennit-0.4.3-py3-none-any.whl.metadata (9.6 kB)\n",
            "  Downloading zennit-0.4.2-py3-none-any.whl.metadata (9.2 kB)\n",
            "  Downloading zennit-0.4.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "  Downloading zennit-0.4.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "  Downloading zennit-0.3.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "  Downloading zennit-0.3.2-py3-none-any.whl.metadata (9.2 kB)\n",
            "  Downloading zennit-0.3.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "  Downloading zennit-0.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "  Downloading zennit-0.2.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "\u001b[31mERROR: Cannot install torchvision==0.20.1+cu124, zennit, zennit-crp and zennit-crp==0.6.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.20.1+cu124 depends on torch==2.5.1\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.21.0 depends on torch==2.6.0\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.20.1 depends on torch==2.5.1\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.20.0 depends on torch==2.5.0\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.19.1 depends on torch==2.4.1\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.19.0 depends on torch==2.4.0\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.18.1 depends on torch==2.3.1\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.18.0 depends on torch==2.3.0\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.17.2 depends on torch==2.2.2\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.17.1 depends on torch==2.2.1\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.17.0 depends on torch==2.2.0\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.16.2 depends on torch==2.1.2\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.16.1 depends on torch==2.1.1\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.16.0 depends on torch==2.1.0\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.15.2 depends on torch==2.0.1\n",
            "    zennit-crp 0.6.0 depends on torch<2.0.0 and >=1.7.0\n",
            "    zennit 0.2.1 depends on torch>=1.7.0\n",
            "    torchvision 0.15.1 depends on torch==2.0.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install matplotlib numpy pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5xawCg6Mpa3",
        "outputId": "230a5b71-054a-4e13-d576-ae341317b764"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'zennit<=0.4.6'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4niXhSxXQTuv",
        "outputId": "fd10ade9-d0df-4f6c-f84e-056561915803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zennit<=0.4.6\n",
            "  Using cached zennit-0.4.6-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from zennit<=0.4.6) (8.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from zennit<=0.4.6) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from zennit<=0.4.6) (11.1.0)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from zennit<=0.4.6) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from zennit<=0.4.6) (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->zennit<=0.4.6) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->zennit<=0.4.6) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->zennit<=0.4.6) (3.0.2)\n",
            "Downloading zennit-0.4.6-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zennit\n",
            "Successfully installed zennit-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8Es5hyWMpa6",
        "outputId": "21a11805-6ca1-40a4-d9ea-124236660269"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/zennitcrp/crp')\n",
        "sys.path.append('/content/zennitcrp')"
      ],
      "metadata": {
        "id": "pWkFiz2cN-70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "redémarreret renommer zennitcrp\n"
      ],
      "metadata": {
        "id": "k4iYMnXkv9Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/zennitcrp/crp')\n",
        "sys.path.append('/content/zennitcrp')"
      ],
      "metadata": {
        "id": "MQYeXJaVx0MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import crp"
      ],
      "metadata": {
        "id": "HeP0bdVJwmF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "from zennit.composites import EpsilonPlusFlat\n",
        "from zennit.canonizers import SequentialMergeBatchNorm\n",
        "from zennitcrp.crp.attribution import CondAttribution\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "from torchvision.models.vgg import vgg16_bn\n",
        "import json"
      ],
      "metadata": {
        "id": "U2kmq7USMpa7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 121MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = vgg16_bn(True).to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7yM6einMpa8",
        "outputId": "1c6ad92d-9bf5-4470-fb7f-7e7c30f826e9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "CLASSE_PREDICTED = \"classe_predicted\"\n",
        "PROBABILITY = \"probability\"\n",
        "FEATURES = \"features\""
      ],
      "metadata": {
        "id": "2gNHL9caMpa9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "features_per_layer = {\n",
        "    0: 64,\n",
        "    3: 64,\n",
        "    7: 128,\n",
        "    10: 128,\n",
        "    14: 256,\n",
        "    17: 256,\n",
        "    20: 256,\n",
        "    24: 512,\n",
        "    27: 512,\n",
        "    30: 512,\n",
        "    34: 512,\n",
        "    37: 512,\n",
        "    40: 512\n",
        "}"
      ],
      "metadata": {
        "id": "TdaRYA8oMpa9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compute_feature_importance(model, input_tensor, layer_idx, num_features, pred_class):\n",
        "    \"\"\"\n",
        "    Calcule l'importance de chaque feature d'une couche donnée pour une classe prédite.\n",
        "\n",
        "    Arguments :\n",
        "    - model : le modèle VGG16\n",
        "    - input_tensor : l'image d'entrée sous forme de tenseur\n",
        "    - layer_idx : l'index de la couche (ex : 40)\n",
        "    - num_features : le nombre total de features dans cette couche (ex : 512)\n",
        "    - pred_class : la classe prédite initialement\n",
        "\n",
        "    Retourne :\n",
        "    - Un dictionnaire {feature_idx : importance} trié par importance décroissante\n",
        "    \"\"\"\n",
        "    input_tensor.requires_grad = True\n",
        "    # Obtenir la probabilité originale de la classe prédite\n",
        "    with torch.no_grad():\n",
        "        output_original = model(input_tensor)\n",
        "        probs_original = torch.nn.functional.softmax(output_original, dim=1)\n",
        "        original_score = probs_original[0, pred_class].item()\n",
        "\n",
        "    feature_importance = {}\n",
        "\n",
        "    # Désactiver chaque feature une par une et mesurer l'impact\n",
        "    for feature_idx in range(num_features):\n",
        "        def zero_out_feature(module, input, output, feature_idx=feature_idx):\n",
        "            output[:, feature_idx, :, :] = 0  # Désactiver la feature\n",
        "            return output\n",
        "\n",
        "        # Ajouter un hook temporaire\n",
        "        hook = model.features[layer_idx].register_forward_hook(zero_out_feature)\n",
        "\n",
        "        # Faire une prédiction avec la feature désactivée\n",
        "        with torch.no_grad():\n",
        "            output_disabled = model(input_tensor)\n",
        "            probs_disabled = torch.nn.functional.softmax(output_disabled, dim=1)\n",
        "            new_score = probs_disabled[0, pred_class].item()\n",
        "\n",
        "        # Supprimer le hook\n",
        "        hook.remove()\n",
        "\n",
        "        # Calcul de l'importance\n",
        "        importance = original_score - new_score\n",
        "        feature_importance[feature_idx] = float(importance)\n",
        "\n",
        "        # Affichage de progression\n",
        "        #print(f\"Feature {feature_idx+1}/{num_features} - Importance: {importance:.4f}\")\n",
        "\n",
        "    # Trier les features par importance décroissante\n",
        "    sorted_importance = dict(sorted(feature_importance.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    return sorted_importance\n"
      ],
      "metadata": {
        "id": "mvLX84KxMpa-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def processPicture(global_dictionary : dict, picture_path : str = \"/content/drive/My Drive/PER/data\", output_heatmaps_path :str = \"/content/drive/My Drive/PER/save/heatmaps\"):\n",
        "    local_dictionary = {}\n",
        "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    image = Image.open(picture_path).convert(\"RGB\")\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    input_tensor.requires_grad = True\n",
        "\n",
        "    output = model(input_tensor)\n",
        "    pred_class = torch.argmax(output, dim=1).item()\n",
        "    probs = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "    local_dictionary[CLASSE_PREDICTED] = pred_class\n",
        "    local_dictionary[PROBABILITY] = probs[0, pred_class]\n",
        "\n",
        "    composite = EpsilonPlusFlat([SequentialMergeBatchNorm()])\n",
        "    attribution = CondAttribution(model, no_param_grad=True)\n",
        "\n",
        "    features_dict = {}\n",
        "    layers_heatmaps = {}\n",
        "    for layer_idx, num_features in features_per_layer.items():\n",
        "        all_heatmaps = []\n",
        "        num_feature_per_batch = 8\n",
        "        index = 0\n",
        "        borne_sup = 0\n",
        "        while borne_sup != num_features:\n",
        "            borne_sup = min((index+1)*num_feature_per_batch, num_features)\n",
        "            conditions = [{\"y\": [40], \"features.40\": [j]} for j in range(index*num_feature_per_batch, borne_sup)]\n",
        "            heatmaps, _, _, _ = attribution(input_tensor, conditions, composite)\n",
        "            all_heatmaps.append(heatmaps)\n",
        "            index += 1\n",
        "        heatmaps = np.concatenate([heatmap.cpu().numpy() for heatmap in all_heatmaps], axis=0)\n",
        "        #heatmaps = np.concatenate(all_heatmaps, axis=0)\n",
        "        layers_heatmaps[layer_idx] = heatmaps\n",
        "\n",
        "        importance_dict = compute_feature_importance(model, input_tensor, layer_idx=layer_idx, num_features=num_features, pred_class=pred_class)\n",
        "\n",
        "        features_dict[layer_idx] = importance_dict\n",
        "\n",
        "    # Normalisation globale sur toutes les heatmaps\n",
        "    min_value = min([heatmaps.min() for heatmaps in layers_heatmaps.values()])\n",
        "    max_value = max([heatmaps.max() for heatmaps in layers_heatmaps.values()])\n",
        "    max_value = max(abs(min_value), abs(max_value))\n",
        "    min_value = -max_value\n",
        "\n",
        "    os.makedirs(output_heatmaps_path, exist_ok=True)\n",
        "    save_path = os.path.join(output_heatmaps_path, f\"{image_name}.npz\")\n",
        "\n",
        "    save_dict = {f\"layer_{idx_layers}\": np.array(heatmaps) for idx_layers, heatmaps in layers_heatmaps.items()}\n",
        "    np.savez(save_path, **save_dict)\n",
        "\n",
        "    local_dictionary[FEATURES] = features_dict\n",
        "    global_dictionary[image_name] = local_dictionary\n",
        "    return global_dictionary"
      ],
      "metadata": {
        "id": "4Qc6nZFQMpa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_list(obj):\n",
        "    if isinstance(obj, torch.Tensor):\n",
        "        return obj.tolist()\n",
        "    raise TypeError(f\"Object of type {type(obj).__name__} is not JSON serializable\")"
      ],
      "metadata": {
        "id": "82NQoKXKwZ-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def create_json_from_data(data, output_filename):\n",
        "    \"\"\"\n",
        "    Fonction qui prend un dictionnaire de données avec des informations sur des images,\n",
        "    et les sauvegarde dans un fichier JSON structuré.\n",
        "\n",
        "    :param data: Dictionnaire avec les données des images.\n",
        "    :param output_filename: Nom du fichier JSON à créer.\n",
        "    \"\"\"\n",
        "    # Créer un dictionnaire pour les données au format désiré\n",
        "    image_data = {}\n",
        "\n",
        "    for image_name, info in data.items():\n",
        "        # Extraire les informations : classe, probabilité, et dictionnaire de features\n",
        "        classe = info[CLASSE_PREDICTED]\n",
        "        probability = info[PROBABILITY]\n",
        "        features = info[FEATURES]\n",
        "\n",
        "        # Ajouter ces informations dans le dictionnaire final\n",
        "        image_data[image_name] = {\n",
        "            CLASSE_PREDICTED: classe,\n",
        "            PROBABILITY: probability,\n",
        "            FEATURES: features\n",
        "        }\n",
        "\n",
        "    # Sauvegarder les données dans un fichier JSON\n",
        "    with open(output_filename, 'w') as json_file:\n",
        "        json.dump(image_data, json_file, indent=4, default=tensor_to_list)\n",
        "    print(f\"Le fichier JSON '{output_filename}' a été créé avec succès.\")"
      ],
      "metadata": {
        "id": "ZyYy89UeMpbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre d'images trouvées : 11\n"
          ]
        }
      ],
      "source": [
        "input_folder = \"/content/drive/My Drive/PER/data\"\n",
        "global_dictionary = {}\n",
        "\n",
        "image_paths = glob(os.path.join(input_folder, \"*.jpeg\"))\n",
        "print(f\"Nombre d'images trouvées : {len(image_paths)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "315sR0GyMpbB",
        "outputId": "ff3af9df-b46e-4692-b152-35b9c86d275b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avoid_images = []"
      ],
      "metadata": {
        "id": "_xafiD120opk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = len(avoid_images)\n",
        "for image_path in image_paths:\n",
        "    global_dictionary = {}\n",
        "    if image_path in avoid_images:\n",
        "        print(f\"Image {image_path} avoid\")\n",
        "        continue\n",
        "    global_dictionary = processPicture(global_dictionary, image_path)\n",
        "    avoid_images.append(image_path)\n",
        "    print(avoid_images)\n",
        "    create_json_from_data(global_dictionary, f\"/content/drive/My Drive/PER/data{i}.json\")\n",
        "    i = i + 1\n",
        "#create_json_from_data(global_dictionary, \"/content/drive/My Drive/PER/data.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrxjRsQAO39V",
        "outputId": "deac4bb1-614f-4974-863d-4bb1faa25880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data0.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data1.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data2.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg', '/content/drive/My Drive/PER/data/n01622779_2286.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data3.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg', '/content/drive/My Drive/PER/data/n01622779_2286.jpeg', '/content/drive/My Drive/PER/data/n01829413_5429.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data4.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg', '/content/drive/My Drive/PER/data/n01622779_2286.jpeg', '/content/drive/My Drive/PER/data/n01829413_5429.jpeg', '/content/drive/My Drive/PER/data/n01843383_10663.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data5.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg', '/content/drive/My Drive/PER/data/n01622779_2286.jpeg', '/content/drive/My Drive/PER/data/n01829413_5429.jpeg', '/content/drive/My Drive/PER/data/n01843383_10663.jpeg', '/content/drive/My Drive/PER/data/n01843383_2478.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data6.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg', '/content/drive/My Drive/PER/data/n01622779_2286.jpeg', '/content/drive/My Drive/PER/data/n01829413_5429.jpeg', '/content/drive/My Drive/PER/data/n01843383_10663.jpeg', '/content/drive/My Drive/PER/data/n01843383_2478.jpeg', '/content/drive/My Drive/PER/data/n01843383_6110.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data7.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg', '/content/drive/My Drive/PER/data/n01622779_2286.jpeg', '/content/drive/My Drive/PER/data/n01829413_5429.jpeg', '/content/drive/My Drive/PER/data/n01843383_10663.jpeg', '/content/drive/My Drive/PER/data/n01843383_2478.jpeg', '/content/drive/My Drive/PER/data/n01843383_6110.jpeg', '/content/drive/My Drive/PER/data/n02391049_36.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data8.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg', '/content/drive/My Drive/PER/data/n01622779_2286.jpeg', '/content/drive/My Drive/PER/data/n01829413_5429.jpeg', '/content/drive/My Drive/PER/data/n01843383_10663.jpeg', '/content/drive/My Drive/PER/data/n01843383_2478.jpeg', '/content/drive/My Drive/PER/data/n01843383_6110.jpeg', '/content/drive/My Drive/PER/data/n02391049_36.jpeg', '/content/drive/My Drive/PER/data/n02437312_2657.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data9.json' a été créé avec succès.\n",
            "['/content/drive/My Drive/PER/data/n01443537_518.jpeg', '/content/drive/My Drive/PER/data/n01484850_19861.jpeg', '/content/drive/My Drive/PER/data/n01494475_7789.jpeg', '/content/drive/My Drive/PER/data/n01622779_2286.jpeg', '/content/drive/My Drive/PER/data/n01829413_5429.jpeg', '/content/drive/My Drive/PER/data/n01843383_10663.jpeg', '/content/drive/My Drive/PER/data/n01843383_2478.jpeg', '/content/drive/My Drive/PER/data/n01843383_6110.jpeg', '/content/drive/My Drive/PER/data/n02391049_36.jpeg', '/content/drive/My Drive/PER/data/n02437312_2657.jpeg', '/content/drive/My Drive/PER/data/n02480495_824.jpeg']\n",
            "Le fichier JSON '/content/drive/My Drive/PER/data10.json' a été créé avec succès.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#['/content/drive/My Drive/PER/data/n01829413_46.jpeg', '/content/drive/My Drive/PER/data/n01443537_130.jpeg', '/content/drive/My Drive/PER/data/n01484850_198.jpeg', '/content/drive/My Drive/PER/data/n01494475_20.jpeg', '/content/drive/My Drive/PER/data/n01622779_172.jpeg', '/content/drive/My Drive/PER/data/n01843383_547.jpeg', '/content/drive/My Drive/PER/data/n02071294_4132.jpeg', '/content/drive/My Drive/PER/data/n02071294_4408.jpeg', '/content/drive/My Drive/PER/data/n02391049_544.jpeg', '/content/drive/My Drive/PER/data/n02437312_845.jpeg', '/content/drive/My Drive/PER/data/n02480495_162.jpeg', '/content/drive/My Drive/PER/data/n02480495_824.jpeg', '/content/drive/My Drive/PER/data/n02480855_324.jpeg', '/content/drive/My Drive/PER/data/n02486410_86.jpeg', '/content/drive/My Drive/PER/data/n02492035_742.jpeg', '/content/drive/My Drive/PER/data/n02504013_189.jpeg', '/content/drive/My Drive/PER/data/n02510455_1238.jpeg', '/content/drive/My Drive/PER/data/n02510455_190.jpeg']"
      ],
      "metadata": {
        "id": "-iNJq1_4Uxg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}