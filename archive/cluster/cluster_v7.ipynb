{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "from zennitcrp.crp.attribution import CondAttribution\n",
    "import os\n",
    "import json\n",
    "from zennit.composites import EpsilonPlusFlat\n",
    "from zennit.canonizers import SequentialMergeBatchNorm\n",
    "from crp.attribution import CondAttribution\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import hdbscan\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import torch\n",
    "from torchvision.models.vgg import vgg16_bn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def analysis_clusters(methods_cluster,\n",
    "                      heatmaps_scaled,\n",
    "                      picture_name,\n",
    "                      cluster_folder_save_path,\n",
    "                      min_cluster : int = 2,\n",
    "                      max_cluster : int = 16):\n",
    "    cluster_range = range(min_cluster, max_cluster)\n",
    "    silhouette_scores = {method: [] for method in methods_cluster}\n",
    "    GMM_dict = {}\n",
    "    KMeans_dict = {}\n",
    "    Spectral_dict = {}\n",
    "    Agglomerative_dict = {}\n",
    "\n",
    "    for n_clusters in cluster_range:\n",
    "        for method_name, clustering_function in methods_cluster.items():\n",
    "            model = clustering_function(n_clusters)\n",
    "            labels = model.fit_predict(heatmaps_scaled)\n",
    "\n",
    "            if len(set(labels)) > 1:\n",
    "                score = silhouette_score(heatmaps_scaled, labels)\n",
    "            else:\n",
    "                score = -1\n",
    "            silhouette_scores[method_name].append(score)\n",
    "\n",
    "            if method_name == GMM_CONST:\n",
    "                GMM_dict[n_clusters] = labels\n",
    "            elif method_name == KMEANS_CONST:\n",
    "                KMeans_dict[n_clusters] = labels\n",
    "            elif method_name == SPECTRAL_CONST:\n",
    "                Spectral_dict[n_clusters] = labels\n",
    "            elif method_name == AGGLOMERATIVE_CONST:\n",
    "                Agglomerative_dict[n_clusters] = labels\n",
    "\n",
    "    general_dict = {}\n",
    "    general_score_dict = {}\n",
    "\n",
    "    for method_name, _ in methods_cluster.items():\n",
    "        if method_name == GMM_CONST:\n",
    "            list_dict_keys = list(GMM_dict.keys())\n",
    "            for key in list_dict_keys:\n",
    "                general_dict[f\"{key}_{GMM_CONST}\"] = np.array(GMM_dict[key])\n",
    "            general_score_dict[f\"{GMM_CONST}\"] = np.array(silhouette_scores[GMM_CONST])\n",
    "        elif method_name == KMEANS_CONST:\n",
    "            list_dict_keys = list(KMeans_dict.keys())\n",
    "            for key in list_dict_keys:\n",
    "                general_dict[f\"{key}_{KMEANS_CONST}\"] = np.array(KMeans_dict[key])\n",
    "            general_score_dict[f\"{KMEANS_CONST}\"] = np.array(silhouette_scores[KMEANS_CONST])\n",
    "        elif method_name == SPECTRAL_CONST:\n",
    "            list_dict_keys = list(Spectral_dict.keys())\n",
    "            for key in list_dict_keys:\n",
    "                general_dict[f\"{key}_{SPECTRAL_CONST}\"] = np.array(Spectral_dict[key])\n",
    "            general_score_dict[f\"{SPECTRAL_CONST}\"] = np.array(silhouette_scores[SPECTRAL_CONST])\n",
    "        elif method_name == AGGLOMERATIVE_CONST:\n",
    "            list_dict_keys = list(Agglomerative_dict.keys())\n",
    "            for key in list_dict_keys:\n",
    "                general_dict[f\"{key}_{AGGLOMERATIVE_CONST}\"] = np.array(Agglomerative_dict[key])\n",
    "            general_score_dict[f\"{AGGLOMERATIVE_CONST}\"] = np.array(silhouette_scores[AGGLOMERATIVE_CONST])\n",
    "    general_score_dict[f\"{MIN_CLUSTER_CONST}\"] = min_cluster\n",
    "    general_score_dict[f\"{MAX_CLUSTER_CONST}\"] = max_cluster\n",
    "\n",
    "    np.savez(f\"{cluster_folder_save_path}/clusters_{picture_name}.npz\", **general_dict)\n",
    "    np.savez(f\"{cluster_folder_save_path}/scores_{picture_name}.npz\", **general_score_dict)\n",
    "    return silhouette_scores, cluster_range"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def plot_silhouette_scores(silhouette_scores, cluster_range, file_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for method, scores in silhouette_scores.items():\n",
    "        ax.plot(cluster_range, scores, marker='o', linestyle='-', label=method)\n",
    "\n",
    "    ax.set_xlabel(\"Nombre de Clusters\")\n",
    "    ax.set_ylabel(\"Silhouette Score\")\n",
    "    ax.set_title(f\"Comparaison des Algorithmes de Clustering\\n{file_name}\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_and_process_normalized(file_name : str,\n",
    "                                base_path,\n",
    "                                layer_name : str = \"layer_40\"):\n",
    "    data = np.load(f\"{base_path}/heatmap/{file_name}\")\n",
    "    heatmaps = data[layer_name]\n",
    "    heatmaps = np.abs(heatmaps)\n",
    "    heatmaps_scaled = np.zeros_like(heatmaps)\n",
    "    for i in range(heatmaps.shape[0]):\n",
    "        min_val = np.min(heatmaps[i])\n",
    "        max_val = np.max(heatmaps[i])\n",
    "        if max_val > min_val:  # Éviter division par zéro\n",
    "            heatmaps_scaled[i] = (heatmaps[i] - min_val) / (max_val - min_val)\n",
    "    heatmaps_flat = heatmaps_scaled.reshape(heatmaps_scaled.shape[0], -1)\n",
    "    return heatmaps, heatmaps_flat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def compute_feature_importance(model, input_tensor, layer_idx, num_features, pred_class):\n",
    "    \"\"\"\n",
    "    Calcule l'importance de chaque feature d'une couche donnée pour une classe prédite.\n",
    "\n",
    "    Arguments :\n",
    "    - model : le modèle VGG16\n",
    "    - input_tensor : l'image d'entrée sous forme de tenseur\n",
    "    - layer_idx : l'index de la couche (ex : 40)\n",
    "    - num_features : le nombre total de features dans cette couche (ex : 512)\n",
    "    - pred_class : la classe prédite initialement\n",
    "\n",
    "    Retourne :\n",
    "    - Un dictionnaire {feature_idx : importance} trié par importance décroissante\n",
    "    \"\"\"\n",
    "    input_tensor.requires_grad = True\n",
    "    # Obtenir la probabilité originale de la classe prédite\n",
    "    with torch.no_grad():\n",
    "        output_original = model(input_tensor)\n",
    "        probs_original = torch.nn.functional.softmax(output_original, dim=1)\n",
    "        original_score = probs_original[0, pred_class].item()\n",
    "\n",
    "    feature_importance = {}\n",
    "\n",
    "    # Désactiver chaque feature une par une et mesurer l'impact\n",
    "    for feature_idx in range(num_features):\n",
    "        def zero_out_feature(module, input, output, feature_idx=feature_idx):\n",
    "            output[:, feature_idx, :, :] = 0  # Désactiver la feature\n",
    "            return output\n",
    "\n",
    "        # Ajouter un hook temporaire\n",
    "        hook = model.features[layer_idx].register_forward_hook(zero_out_feature)\n",
    "\n",
    "        # Faire une prédiction avec la feature désactivée\n",
    "        with torch.no_grad():\n",
    "            output_disabled = model(input_tensor)\n",
    "            probs_disabled = torch.nn.functional.softmax(output_disabled, dim=1)\n",
    "            new_score = probs_disabled[0, pred_class].item()\n",
    "\n",
    "        # Supprimer le hook\n",
    "        hook.remove()\n",
    "\n",
    "        # Calcul de l'importance\n",
    "        importance = original_score - new_score\n",
    "        feature_importance[feature_idx] = float(importance)\n",
    "\n",
    "        # Affichage de progression\n",
    "        #print(f\"Feature {feature_idx+1}/{num_features} - Importance: {importance:.4f}\")\n",
    "\n",
    "    # Trier les features par importance décroissante\n",
    "    sorted_importance = dict(sorted(feature_importance.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return sorted_importance\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def processPicture(model,\n",
    "                   transform,\n",
    "                   global_dictionary : dict,\n",
    "                   picture_path : str,\n",
    "                   heatmap_folder_save_path : str,\n",
    "                   device : str = \"cpu\"):\n",
    "    local_dictionary = {}\n",
    "    image_name = os.path.splitext(os.path.basename(picture_path))[0]\n",
    "    image = Image.open(picture_path).convert(\"RGB\")\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    input_tensor.requires_grad = True\n",
    "\n",
    "    output = model(input_tensor)\n",
    "    pred_class = torch.argmax(output, dim=1).item()\n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    local_dictionary[CLASSE_PREDICTED] = pred_class\n",
    "    local_dictionary[PROBABILITY] = probs[0, pred_class]\n",
    "\n",
    "    composite = EpsilonPlusFlat([SequentialMergeBatchNorm()])\n",
    "    attribution = CondAttribution(model, no_param_grad=True)\n",
    "\n",
    "    features_dict = {}\n",
    "    layers_heatmaps = {}\n",
    "    for layer_idx, num_features in features_per_layer.items():\n",
    "        all_heatmaps = []\n",
    "        num_feature_per_batch = 8\n",
    "        index = 0\n",
    "        borne_sup = 0\n",
    "        while borne_sup != num_features:\n",
    "            borne_sup = min((index+1)*num_feature_per_batch, num_features)\n",
    "            conditions = [{\"y\": [40], \"features.40\": [j]} for j in range(index*num_feature_per_batch, borne_sup)]\n",
    "            heatmaps, _, _, _ = attribution(input_tensor, conditions, composite)\n",
    "            all_heatmaps.append(heatmaps)\n",
    "            index += 1\n",
    "        heatmaps = np.concatenate([heatmap.cpu().numpy() for heatmap in all_heatmaps], axis=0)\n",
    "        #heatmaps = np.concatenate(all_heatmaps, axis=0)\n",
    "        layers_heatmaps[layer_idx] = heatmaps\n",
    "\n",
    "        importance_dict = compute_feature_importance(model, input_tensor, layer_idx=layer_idx, num_features=num_features, pred_class=pred_class)\n",
    "\n",
    "        features_dict[layer_idx] = importance_dict\n",
    "\n",
    "    # Normalisation globale sur toutes les heatmaps\n",
    "    min_value = min([heatmaps.min() for heatmaps in layers_heatmaps.values()])\n",
    "    max_value = max([heatmaps.max() for heatmaps in layers_heatmaps.values()])\n",
    "    max_value = max(abs(min_value), abs(max_value))\n",
    "    min_value = -max_value\n",
    "\n",
    "    save_path = os.path.join(heatmap_folder_save_path, f\"{image_name}.npz\")\n",
    "\n",
    "    save_dict = {f\"layer_{idx_layers}\": np.array(heatmaps) for idx_layers, heatmaps in layers_heatmaps.items()}\n",
    "    np.savez(save_path, **save_dict)\n",
    "\n",
    "    local_dictionary[FEATURES] = features_dict\n",
    "    global_dictionary[image_name] = local_dictionary\n",
    "    return global_dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def tensor_to_list(obj):\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        return obj.tolist()\n",
    "    raise TypeError(f\"Object of type {type(obj).__name__} is not JSON serializable\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_filename_without_extension(path: str) -> str:\n",
    "    return os.path.splitext(os.path.basename(path))[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def create_json_from_data(data, output_filename):\n",
    "    \"\"\"\n",
    "    Fonction qui prend un dictionnaire de données avec des informations sur des images,\n",
    "    et les sauvegarde dans un fichier JSON structuré.\n",
    "\n",
    "    :param data: Dictionnaire avec les données des images.\n",
    "    :param output_filename: Nom du fichier JSON à créer.\n",
    "    \"\"\"\n",
    "    # Créer un dictionnaire pour les données au format désiré\n",
    "    image_data = {}\n",
    "\n",
    "    for image_name, info in data.items():\n",
    "        # Extraire les informations : classe, probabilité, et dictionnaire de features\n",
    "        classe = info[CLASSE_PREDICTED]\n",
    "        probability = info[PROBABILITY]\n",
    "        features = info[FEATURES]\n",
    "\n",
    "        # Ajouter ces informations dans le dictionnaire final\n",
    "        image_data[image_name] = {\n",
    "            CLASSE_PREDICTED: classe,\n",
    "            PROBABILITY: probability,\n",
    "            FEATURES: features\n",
    "        }\n",
    "\n",
    "    # Sauvegarder les données dans un fichier JSON\n",
    "    with open(output_filename, 'w') as json_file:\n",
    "        json.dump(image_data, json_file, indent=4, default=tensor_to_list)\n",
    "    print(f\"Le fichier JSON '{output_filename}' a été créé avec succès.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CLASSE_PREDICTED = \"classe_predicted\"\n",
    "PROBABILITY = \"probability\"\n",
    "FEATURES = \"features\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "GMM_CONST = \"GMM\"\n",
    "KMEANS_CONST = \"KMeans\"\n",
    "SPECTRAL_CONST = \"SpectralClustering\"\n",
    "AGGLOMERATIVE_CONST = \"AgglomerativeClustering\"\n",
    "HDBSCAN_CONST = \"HDBSCAN\"\n",
    "MIN_CLUSTER_CONST = \"min_cluster\"\n",
    "MAX_CLUSTER_CONST = \"max_cluster\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO : modifier pour mettre le bon chemin\n",
    "picture_folder_path chemin vers le dossier avec les photos\n",
    "cluster_folder_save_path chemin où sont sauvegarder les .npz des heatmaps et l'importance de chaque features dans un .json\n",
    "heatmap_folder_save_path chemin où sont sauvegarder les .npz des clusters et les scores de chaque méthode de clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "base_path = \"./data/v6/clusters\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getDevice():\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getModel(device : str = \"cpu\"):\n",
    "    model_vgg16 = vgg16_bn(True).to(device)\n",
    "    model_vgg16.eval()\n",
    "    return model_vgg16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getTransform():\n",
    "    transform_vgg16 = T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    return transform_vgg16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_heatmap_from_image(model,\n",
    "                    transform,\n",
    "                    device,\n",
    "                    heatmap_folder_save_path : str,\n",
    "                    list_image_paths : list,\n",
    "                    avoid_images : list = None):\n",
    "    if avoid_images is None:\n",
    "        avoid_images = []\n",
    "    for image_path in list_image_paths:\n",
    "        global_dictionary = {}\n",
    "        if image_path in avoid_images:\n",
    "            print(f\"Image {image_path} avoid\")\n",
    "            continue\n",
    "        image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        global_dictionary = processPicture(model=model,\n",
    "                                           transform=transform,\n",
    "                                           global_dictionary = global_dictionary,\n",
    "                                           picture_path = image_path,\n",
    "                                           heatmap_folder_save_path=heatmap_folder_save_path,\n",
    "                                           device=device)\n",
    "        avoid_images.append(image_path)\n",
    "        create_json_from_data(global_dictionary, f\"{heatmap_folder_save_path}/{image_name}_importance.json\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_all_image_paths(picture_folder_path : str, extension : str = \"jpeg\"):\n",
    "    return glob(os.path.join(picture_folder_path, f\"*.{extension}\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def perform_kmeans_clustering(heatmaps_scaled, n_clusters : int = 10):\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=7)\n",
    "    labels = model.fit_predict(heatmaps_scaled)\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_and_process_normalized(file_name_with_extension : str,\n",
    "                                base_path,\n",
    "                                layer_name : str = \"layer_40\"):\n",
    "    data = np.load(f\"{base_path}/heatmap/{file_name_with_extension}\")\n",
    "    heatmaps = data[layer_name]\n",
    "    heatmaps = np.abs(heatmaps)\n",
    "    heatmaps_scaled = np.zeros_like(heatmaps)\n",
    "    for i in range(heatmaps.shape[0]):\n",
    "        min_val = np.min(heatmaps[i])\n",
    "        max_val = np.max(heatmaps[i])\n",
    "        if max_val > min_val:  # Éviter division par zéro\n",
    "            heatmaps_scaled[i] = (heatmaps[i] - min_val) / (max_val - min_val)\n",
    "    heatmaps_flat = heatmaps_scaled.reshape(heatmaps_scaled.shape[0], -1)\n",
    "    return heatmaps, heatmaps_flat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def indices_par_valeur(lst):\n",
    "    arr = np.array(lst)\n",
    "    return {val: np.where(arr == val)[0].tolist() for val in np.unique(arr)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dictionary_one_hot_encoding(lst):\n",
    "    arr = np.array(lst)\n",
    "    indices_dict = {}\n",
    "    for val in np.unique(arr):\n",
    "        binaire = np.zeros(len(arr), dtype=int)  # Crée une liste de zéros de taille 512\n",
    "        binaire[np.where(arr == val)[0]] = 1     # Met un 1 aux indices correspondant à la valeur\n",
    "        indices_dict[val] = binaire.tolist()\n",
    "    return indices_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_number_big_clusters = 10 #the number of features different from all the class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_state = 7\n",
    "n_clusters_per_picture = 10\n",
    "avoid_images = []\n",
    "save_all_hot_encoding = True\n",
    "save_cluster = True\n",
    "extract_heatmap = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "extrait toutes els heatmaps des fichiers dans \"{base_path}/pictures\"\n",
    "Ensuite fait cluster KMeans à 10.\n",
    "Ensuite fait un KMean à 10 de type big-cluster dessus\n",
    "Ensuite fait PCA et TSNE pour visualiser les clusters\n",
    "Sauvegarde dans un dictionnaire avec chaque big-cluster les features associé."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def a(base_path : str,\n",
    "      final_number_big_clusters : int = 10,\n",
    "      extract_heatmap : bool = True,\n",
    "      save_cluster : bool = True,\n",
    "      save_all_hot_encoding : bool = True,\n",
    "      avoid_images : list = None,\n",
    "      n_clusters_per_picture : int = 10,\n",
    "      random_state : int = 7):\n",
    "    device = getDevice()\n",
    "    model = getModel(device)\n",
    "    transform = getTransform()\n",
    "\n",
    "    heatmap_folder_save_path = f\"{base_path}/heatmap\"\n",
    "    image_paths = f\"{base_path}/pictures\"\n",
    "    #verification paths\n",
    "\n",
    "    list_image_paths = get_all_image_paths(image_paths)\n",
    "    if avoid_images is None:\n",
    "        avoid_images = []\n",
    "    if extract_heatmap :\n",
    "        extract_heatmap_from_image(device, model, transform, heatmap_folder_save_path, list_image_paths, avoid_images)\n",
    "\n",
    "    if save_cluster:\n",
    "        dict_label = {}\n",
    "        dict_label[\"n_clusters\"] = 10\n",
    "        for file_name_with_extension in os.listdir(f\"{base_path}/heatmap\"):\n",
    "            file_name = os.path.splitext(file_name_with_extension)[0]\n",
    "            _, heatmaps_scaled = load_and_process_normalized(file_name_with_extension, base_path)\n",
    "            labels = perform_kmeans_clustering(heatmaps_scaled, n_clusters=n_clusters_per_picture)\n",
    "\n",
    "            dict_label[file_name] = labels\n",
    "        np.savez(f\"{base_path}/clusters/labels.npz\", **dict_label)\n",
    "\n",
    "\n",
    "\n",
    "    if save_all_hot_encoding:\n",
    "        dict_label = np.load(f\"{base_path}/clusters/labels.npz\")\n",
    "        all_hot_encoding = np.array()\n",
    "        for file_name, cluster_label in dict_label.items():\n",
    "            index_in_each_cluster = dictionary_one_hot_encoding(cluster_label)\n",
    "            local_hot_encoding = np.array(list(index_in_each_cluster.values()))\n",
    "            all_hot_encoding = np.concatenate((all_hot_encoding, local_hot_encoding), axis=0)\n",
    "        np.savez(f\"{base_path}/clusters/hot_encoding.npz\", all_hot_encoding=all_hot_encoding)\n",
    "\n",
    "    all_hot_encoding = np.load(f\"{base_path}/clusters/hot_encoding.npz\")[\"all_hot_encoding\"]\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(np.stack(all_hot_encoding))\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=random_state, perplexity=30, n_iter=1000)\n",
    "    tsne_result = tsne.fit_transform(np.stack(all_hot_encoding))\n",
    "\n",
    "    kmeans = KMeans(n_clusters=final_number_big_clusters, random_state=random_state)\n",
    "    big_clusters = kmeans.fit_predict(np.stack(all_hot_encoding))\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(pca_result[:, 0], pca_result[:, 1], c=big_clusters, cmap='tab10', s=5)\n",
    "    plt.colorbar()\n",
    "    plt.title('PCA Visualization with K-Means Clusters')\n",
    "\n",
    "    # 5. Visualisation des clusters avec t-SNE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=big_clusters, cmap='tab10', s=5)\n",
    "    plt.colorbar()\n",
    "    plt.title('t-SNE Visualization with K-Means Clusters')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    clusters_by_big_clusters = indices_par_valeur(big_clusters)\n",
    "    feature_to_big_cluster = {}\n",
    "    for big_cluster_index, clusters_list in clusters_by_big_clusters.items():\n",
    "        for cluster_index in clusters_list:\n",
    "            one_hot_encoding_current_big_cluster = all_hot_encoding[cluster_index]\n",
    "            for feature_index, value in enumerate(one_hot_encoding_current_big_cluster):\n",
    "                if value == 1:\n",
    "                    if feature_index not in feature_to_big_cluster:\n",
    "                        feature_to_big_cluster[feature_index] = [0] * final_number_big_clusters\n",
    "                    feature_to_big_cluster[feature_index][big_cluster_index] += 1\n",
    "\n",
    "    big_bluster_index_to_feature = {}\n",
    "    for feature_index, big_clusters_list in feature_to_big_cluster.items():\n",
    "        best_big_cluster = np.argmax(big_clusters_list)\n",
    "        if best_big_cluster not in big_bluster_index_to_feature:\n",
    "            big_bluster_index_to_feature[best_big_cluster] = []\n",
    "        big_bluster_index_to_feature[best_big_cluster].append(feature_index)\n",
    "\n",
    "    return big_bluster_index_to_feature\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_clusters(dict_feature_per_class: str,\n",
    "                       base_path: str,\n",
    "                       list_image_name_to_test: list):\n",
    "\n",
    "    heatmap_per_class_per_image = {}\n",
    "    for key in dict_feature_per_class.keys():\n",
    "        heatmap_per_image = {}\n",
    "        for image_name in list_image_name_to_test:\n",
    "            heatmap_file_name = f\"{image_name}.npz\"\n",
    "            try:\n",
    "                heatmaps, _ = load_and_process_normalized(heatmap_file_name, base_path, layer_name=\"layer_40\")\n",
    "                feature_index = np.array(dict_feature_per_class[key])\n",
    "\n",
    "                if len(feature_index) > 0:\n",
    "                    cluster_heatmaps = heatmaps[feature_index]\n",
    "                    combined_heatmap = np.sum(cluster_heatmaps, axis=0)\n",
    "                    vmin = min(vmin, combined_heatmap.min())\n",
    "                    vmax = max(vmax, combined_heatmap.max())\n",
    "                    heatmap_per_image[image_name] = combined_heatmap\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_name} for class {key}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        if heatmap_per_image:  # Ne garder que les classes qui ont des heatmaps\n",
    "            heatmap_per_class_per_image[key] = heatmap_per_image\n",
    "\n",
    "    # Filtrer les classes vides et créer la liste des classes à afficher\n",
    "    classes_to_display = [key for key, heatmaps in heatmap_per_class_per_image.items() if heatmaps]\n",
    "\n",
    "    if not classes_to_display:\n",
    "        print(\"No data to display!\")\n",
    "        return\n",
    "\n",
    "    nb_line_adjust = len(classes_to_display)\n",
    "    nb_col_adjust = len(list_image_name_to_test)\n",
    "\n",
    "    # Création de la figure\n",
    "    fig, axes = plt.subplots(nrows=nb_line_adjust,\n",
    "                            ncols=nb_col_adjust,\n",
    "                            figsize=(4 * nb_col_adjust, 4 * nb_line_adjust))\n",
    "    fig.tight_layout(pad=3.0)\n",
    "\n",
    "    # Assurer que axes est toujours 2D\n",
    "    if nb_line_adjust == 1 and nb_col_adjust == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif nb_line_adjust == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    elif nb_col_adjust == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    # Création des visualisations\n",
    "    im = None\n",
    "    for row_idx, class_name in enumerate(classes_to_display):\n",
    "        heatmap_per_image = heatmap_per_class_per_image[class_name]\n",
    "        for col_idx, image_name in enumerate(list_image_name_to_test):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            heatmap = heatmap_per_image.get(image_name)\n",
    "\n",
    "            if heatmap is not None:\n",
    "                im = ax.imshow(heatmap, cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "                ax.set_title(f\"{class_name} - {image_name}\", fontsize=10)\n",
    "            else:\n",
    "                ax.axis('off')\n",
    "            ax.axis('off')\n",
    "\n",
    "    if im is not None:\n",
    "        cbar = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='vertical', fraction=0.05, pad=0.02)\n",
    "        cbar.set_label('Activation Intensity')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "big_bluster_index_to_feature = a(base_path,\n",
    "                              final_number_big_clusters,\n",
    "                              extract_heatmap,\n",
    "                              save_cluster,\n",
    "                              save_all_hot_encoding,\n",
    "                              avoid_images,\n",
    "                              n_clusters_per_picture,\n",
    "                              random_state)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_image_name_to_test = [\n",
    "    'n02437312_2790',\n",
    "    'n02423022_9745',\n",
    "    'n02437616_14498',\n",
    "    'n02437312_3178',\n",
    "    'n02437616_8125',\n",
    "    'n02423022_2042'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualize_clusters(big_bluster_index_to_feature, base_path, list_image_name_to_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
