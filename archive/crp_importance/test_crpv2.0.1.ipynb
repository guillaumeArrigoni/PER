{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.vgg import vgg16_bn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Importer ZennitCRP\n",
    "from zennit.composites import EpsilonPlusFlat\n",
    "from zennit.canonizers import SequentialMergeBatchNorm\n",
    "from crp.attribution import CondAttribution\n",
    "from crp.helper import get_layer_names\n",
    "from crp.concepts import ChannelConcept"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "D:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.vgg import vgg16_bn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = vgg16_bn(True).to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def betterPrintHeatmap(heatmaps):\n",
    "    heatmaps = [h.detach().cpu().numpy() for h in heatmaps[:10]]\n",
    "    number_line = math.ceil(len(heatmaps) / 5)\n",
    "    fig, axes = plt.subplots(number_line, 6, figsize=(18, 6))\n",
    "\n",
    "    vmin = min(h.min() for h in heatmaps)\n",
    "    vmax = max(h.max() for h in heatmaps)\n",
    "    print(f\"Min value for a pixel: {vmin}, Max value for a pixel: {vmax}\")\n",
    "    heatmap_element = 0\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        row, col = divmod(i, 6)\n",
    "        if heatmap_element >= len(heatmaps):\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        if col > 4:\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        im = ax.imshow(heatmaps[heatmap_element], cmap=\"seismic\", interpolation=\"nearest\", vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"Heatmap {heatmap_element+1}\")\n",
    "        heatmap_element += 1\n",
    "\n",
    "\n",
    "    # Ajouter une barre de couleur verticale à droite de la grille\n",
    "    fig.colorbar(im, ax=axes, orientation='vertical', location='right')\n",
    "\n",
    "    # Ajuster l'espacement pour que les heatmaps ne se chevauchent pas\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    # Afficher la grille\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def compute_feature_importance(model, input_tensor, layer_idx, allFeaturesIDX, pred_class):\n",
    "    \"\"\"\n",
    "    Calcule l'importance globale des features d'une couche donnée pour une classe prédite\n",
    "    après désactivation de toutes les features spécifiées dans allFeaturesIDX.\n",
    "\n",
    "    Arguments :\n",
    "    - model : le modèle VGG16\n",
    "    - input_tensor : l'image d'entrée sous forme de tenseur\n",
    "    - layer_idx : l'index de la couche (ex : 40)\n",
    "    - allFeaturesIDX : liste des indices des features à désactiver (list)\n",
    "    - pred_class : la classe prédite initialement\n",
    "\n",
    "    Retourne :\n",
    "    - La différence entre le score original et le score après désactivation\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtenir la probabilité originale de la classe prédite\n",
    "    with torch.no_grad():\n",
    "        output_original = model(input_tensor)\n",
    "        probs_original = torch.nn.functional.softmax(output_original, dim=1)\n",
    "        original_score = probs_original[0, pred_class].item()\n",
    "\n",
    "    def zero_out_features(module, input, output):\n",
    "        for idx in allFeaturesIDX:\n",
    "            output[:, idx, :, :] = 0  # Désactiver chaque feature spécifiée\n",
    "        return output\n",
    "\n",
    "    # Ajouter un hook temporaire\n",
    "    hook = model.features[layer_idx].register_forward_hook(zero_out_features)\n",
    "\n",
    "    # Faire une prédiction avec les features désactivées\n",
    "    with torch.no_grad():\n",
    "        output_disabled = model(input_tensor)\n",
    "        probs_disabled = torch.nn.functional.softmax(output_disabled, dim=1)\n",
    "        new_score = probs_disabled[0, pred_class].item()\n",
    "\n",
    "    # Supprimer le hook\n",
    "    hook.remove()\n",
    "\n",
    "    # Calcul de l'importance globale des features désactivées\n",
    "    importance = original_score - new_score\n",
    "    print(original_score)\n",
    "    print(new_score)\n",
    "    print(f\"Importance globale après désactivation des features : {importance:.4f}\")\n",
    "\n",
    "    return importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.vgg import vgg16_bn\n",
    "\n",
    "def compute_feature_importance_all_input_tensor(model, all_imput_tensor_of_path, layer_idx, num_features, pred_class):\n",
    "    sum_original_score = 0\n",
    "    mean_original_score = 0\n",
    "    feature_score = {}\n",
    "    feature_importance = {}\n",
    "    for _, tuple_input_pred_prob in all_imput_tensor_of_path.items() :\n",
    "        input_tensor = tuple_input_pred_prob[0]\n",
    "        with torch.no_grad():\n",
    "            output_original = model(input_tensor)\n",
    "            probs_original = torch.nn.functional.softmax(output_original, dim=1)\n",
    "            original_score = probs_original[0, pred_class].item()\n",
    "            sum_original_score += original_score\n",
    "    mean_original_score = sum_original_score / len(all_imput_tensor_of_path)\n",
    "\n",
    "    for feature_idx in range(num_features):\n",
    "        def zero_out_feature(module, input, output, feature_idx=feature_idx):\n",
    "            output[:, feature_idx, :, :] = 0  # Désactiver la feature\n",
    "            return output\n",
    "\n",
    "        hook = model.features[layer_idx].register_forward_hook(zero_out_feature)\n",
    "\n",
    "        sum_new_score = 0\n",
    "        mean_new_score = 0\n",
    "        for _, tuple_input_pred_prob in all_imput_tensor_of_path.items():\n",
    "            input_tensor = tuple_input_pred_prob[0]\n",
    "            with torch.no_grad():\n",
    "                output_disabled = model(input_tensor)\n",
    "                probs_disabled = torch.nn.functional.softmax(output_disabled, dim=1)\n",
    "                new_score = probs_disabled[0, pred_class].item()\n",
    "                sum_new_score += new_score\n",
    "        mean_new_score = sum_new_score / len(all_imput_tensor_of_path)\n",
    "        hook.remove()\n",
    "\n",
    "        feature_score[feature_idx] = mean_new_score\n",
    "\n",
    "        # Affichage de progression\n",
    "        importance = mean_original_score - mean_new_score\n",
    "        feature_importance[feature_idx] = importance\n",
    "        print(f\"Feature {feature_idx+1}/{num_features} - Importance: {importance:.4f}\")\n",
    "\n",
    "    sorted_importance = dict(sorted(feature_importance.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return sorted_importance, mean_original_score, feature_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_images(folder_path):\n",
    "    all_imput_tensor_of_path = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpeg\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            all_imput_tensor_of_path[filename] = input_tensor\n",
    "            #print(f\"Image {filename} chargée et transformée.\")\n",
    "    return all_imput_tensor_of_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def separate_well_bad_predicted(all_imput_tensor_of_path, expected_class):\n",
    "    all_wrong_predicted = {}\n",
    "    all_well_predicted = {}\n",
    "    for name, input_tensor in all_imput_tensor_of_path.items() :\n",
    "        with torch.no_grad():\n",
    "            output_original = model(input_tensor)\n",
    "            pred_class = torch.argmax(output_original, dim=1).item()\n",
    "            probs_original = torch.nn.functional.softmax(output_original, dim=1)\n",
    "            original_score = probs_original[0, pred_class].item()\n",
    "        if pred_class != expected_class :\n",
    "            all_wrong_predicted[name] = (input_tensor, pred_class, original_score)\n",
    "            continue\n",
    "        all_well_predicted[name] = (input_tensor, pred_class, original_score)\n",
    "    print(f\"Nombre d'images mal prédites : {len(all_wrong_predicted)}\")\n",
    "    return all_wrong_predicted, all_well_predicted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def positive_negative_features(importance_dict):\n",
    "    positiveFeatures = []\n",
    "    negativeFeatures = []\n",
    "\n",
    "    for feature, importance in importance_dict.items():\n",
    "        if importance >= 0:\n",
    "            positiveFeatures.append(feature)\n",
    "        elif importance < 0:\n",
    "            negativeFeatures.append(feature)\n",
    "\n",
    "    print(f\"Il y a {len(positiveFeatures)} features positives et {len(negativeFeatures)} features négatives.\")\n",
    "    return positiveFeatures, negativeFeatures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folder_path_toucan = r\"C:\\Annexe_D\\PER\\data\\train\\n01843383\" #toucan\n",
    "folder_path_hornbill = r\"C:\\Annexe_D\\PER\\data\\train\\n01829413\"#hornbill"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "expected_class_toucan = 96\n",
    "expected_class_hornbill = 93"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_imput_tensor_of_path_toucan = load_images(folder_path_toucan)\n",
    "all_imput_tensor_of_path_hornbill = load_images(folder_path_hornbill)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_wrong_predicted_toucan, all_well_predicted_toucan = separate_well_bad_predicted(all_imput_tensor_of_path_toucan, expected_class_toucan)\n",
    "all_wrong_predicted_hornbill, all_well_predicted_hornbill = separate_well_bad_predicted(all_imput_tensor_of_path_hornbill, expected_class_hornbill)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1/512 - Importance: -0.0002\n",
      "Feature 2/512 - Importance: 0.0002\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[113], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m importance_dict, mean_original_score, feature_score \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_feature_importance_all_input_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_well_predicted\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_idx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m40\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpected_class\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[112], line 30\u001B[0m, in \u001B[0;36mcompute_feature_importance_all_input_tensor\u001B[1;34m(model, all_imput_tensor_of_path, layer_idx, num_features, pred_class)\u001B[0m\n\u001B[0;32m     28\u001B[0m input_tensor \u001B[38;5;241m=\u001B[39m tuple_input_pred_prob[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 30\u001B[0m     output_disabled \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m     probs_disabled \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39msoftmax(output_disabled, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     32\u001B[0m     new_score \u001B[38;5;241m=\u001B[39m probs_disabled[\u001B[38;5;241m0\u001B[39m, pred_class]\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32mD:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torchvision\\models\\vgg.py:66\u001B[0m, in \u001B[0;36mVGG.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m---> 66\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavgpool(x)\n\u001B[0;32m     68\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mflatten(x, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mD:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    164\u001B[0m     bn_training \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_var \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    166\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001B[39;00m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001B[39;00m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001B[39;00m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001B[39;49;00m\n\u001B[0;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_mean\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\n\u001B[0;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrunning_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrack_running_stats\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbn_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexponential_average_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torch\\nn\\functional.py:2450\u001B[0m, in \u001B[0;36mbatch_norm\u001B[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[0;32m   2447\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m training:\n\u001B[0;32m   2448\u001B[0m     _verify_batch_size(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize())\n\u001B[1;32m-> 2450\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_norm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2451\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcudnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menabled\u001B[49m\n\u001B[0;32m   2452\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "importance_dict_toucan, mean_original_score_toucan, feature_score_toucan = compute_feature_importance_all_input_tensor(model, all_well_predicted_toucan, layer_idx=40, num_features=512, pred_class=expected_class_toucan)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importance_dict_hornbill, mean_original_score_hornbill, feature_score_hornbill = compute_feature_importance_all_input_tensor(model, all_well_predicted_hornbill, layer_idx=40, num_features=512, pred_class=expected_class_hornbill)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 282 features positives et 230 features négatives.\n"
     ]
    }
   ],
   "source": [
    "positiveFeatures_toucan, negativeFeatures_toucan = positive_negative_features(importance_dict_toucan)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positiveFeatures_hornbill, negativeFeatures_hornbill = positive_negative_features(importance_dict_hornbill)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def categorize_indices(dict1, dict2):\n",
    "    both_pos_or_null = []\n",
    "    both_neg = []\n",
    "    first_pos_second_neg = []\n",
    "    first_neg_second_pos = []\n",
    "\n",
    "    all_keys = set(dict1.keys()).union(set(dict2.keys()))\n",
    "\n",
    "    for key in all_keys:\n",
    "        score1 = dict1.get(key, 0)\n",
    "        score2 = dict2.get(key, 0)\n",
    "\n",
    "        if score1 >= 0 and score2 >= 0:\n",
    "            both_pos_or_null.append(key)\n",
    "        elif score1 < 0 and score2 < 0:\n",
    "            both_neg.append(key)\n",
    "        elif score1 >= 0 and score2 < 0:\n",
    "            first_pos_second_neg.append(key)\n",
    "        elif score1 < 0 and score2 >= 0:\n",
    "            first_neg_second_pos.append(key)\n",
    "\n",
    "    return both_pos_or_null, both_neg, first_pos_second_neg, first_neg_second_pos\n",
    "\n",
    "res = categorize_indices(importance_dict_toucan, importance_dict_hornbill)\n",
    "print(\"Les IDX avec score positif ou nul pour les deux :\", res[0])\n",
    "print(\"Les IDX avec score négatif pour les deux :\", res[1])\n",
    "print(\"Les IDX avec premier positif ou nul et deuxième négatif :\", res[2])\n",
    "print(\"Les IDX avec premier négatif et deuxième positif ou nul :\", res[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#number in each list\n",
    "print(f\"both_pos_or_null : {len(res[0])}\")\n",
    "print(f\"both_neg : {len(res[1])}\")\n",
    "print(f\"first_pos_second_neg : {len(res[2])}\")\n",
    "print(f\"first_neg_second_pos : {len(res[3])}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
