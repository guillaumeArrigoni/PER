{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.vgg import vgg16_bn\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Importer ZennitCRP\n",
    "from zennit.composites import EpsilonPlusFlat\n",
    "from zennit.canonizers import SequentialMergeBatchNorm\n",
    "from crp.attribution import CondAttribution\n",
    "from crp.helper import get_layer_names\n",
    "from crp.concepts import ChannelConcept"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "D:\\Programmation\\Projet\\ExplicationAI\\venv\\PER\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.vgg import vgg16_bn\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = vgg16_bn(True).to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def betterPrintHeatmap(heatmaps):\n",
    "    heatmaps = [h.detach().cpu().numpy() for h in heatmaps[:10]]\n",
    "    number_line = math.ceil(len(heatmaps) / 5)\n",
    "    fig, axes = plt.subplots(number_line, 6, figsize=(18, 6))\n",
    "\n",
    "    vmin = min(h.min() for h in heatmaps)\n",
    "    vmax = max(h.max() for h in heatmaps)\n",
    "    print(f\"Min value for a pixel: {vmin}, Max value for a pixel: {vmax}\")\n",
    "    heatmap_element = 0\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        row, col = divmod(i, 6)\n",
    "        if heatmap_element >= len(heatmaps):\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        if col > 4:\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        im = ax.imshow(heatmaps[heatmap_element], cmap=\"seismic\", interpolation=\"nearest\", vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"Heatmap {heatmap_element+1}\")\n",
    "        heatmap_element += 1\n",
    "\n",
    "\n",
    "    # Ajouter une barre de couleur verticale à droite de la grille\n",
    "    fig.colorbar(im, ax=axes, orientation='vertical', location='right')\n",
    "\n",
    "    # Ajuster l'espacement pour que les heatmaps ne se chevauchent pas\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    # Afficher la grille\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "def compute_feature_importance(model, input_tensor, layer_idx, allFeaturesIDX, pred_class):\n",
    "    \"\"\"\n",
    "    Calcule l'importance globale des features d'une couche donnée pour une classe prédite\n",
    "    après désactivation de toutes les features spécifiées dans allFeaturesIDX.\n",
    "\n",
    "    Arguments :\n",
    "    - model : le modèle VGG16\n",
    "    - input_tensor : l'image d'entrée sous forme de tenseur\n",
    "    - layer_idx : l'index de la couche (ex : 40)\n",
    "    - allFeaturesIDX : liste des indices des features à désactiver (list)\n",
    "    - pred_class : la classe prédite initialement\n",
    "\n",
    "    Retourne :\n",
    "    - La différence entre le score original et le score après désactivation\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtenir la probabilité originale de la classe prédite\n",
    "    with torch.no_grad():\n",
    "        output_original = model(input_tensor)\n",
    "        probs_original = torch.nn.functional.softmax(output_original, dim=1)\n",
    "        original_score = probs_original[0, pred_class].item()\n",
    "\n",
    "    def zero_out_features(module, input, output):\n",
    "        for idx in allFeaturesIDX:\n",
    "            output[:, idx, :, :] = 0  # Désactiver chaque feature spécifiée\n",
    "        return output\n",
    "\n",
    "    # Ajouter un hook temporaire\n",
    "    hook = model.features[layer_idx].register_forward_hook(zero_out_features)\n",
    "\n",
    "    # Faire une prédiction avec les features désactivées\n",
    "    with torch.no_grad():\n",
    "        output_disabled = model(input_tensor)\n",
    "        probs_disabled = torch.nn.functional.softmax(output_disabled, dim=1)\n",
    "        new_score = probs_disabled[0, pred_class].item()\n",
    "\n",
    "    # Supprimer le hook\n",
    "    hook.remove()\n",
    "\n",
    "    # Calcul de l'importance globale des features désactivées\n",
    "    importance = original_score - new_score\n",
    "    print(original_score)\n",
    "    print(new_score)\n",
    "    print(f\"Importance globale après désactivation des features : {importance:.4f}\")\n",
    "\n",
    "    return importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.vgg import vgg16_bn\n",
    "\n",
    "def compute_feature_importance_all_input_tensor(model, all_imput_tensor_of_path, layer_idx, num_features, pred_class):\n",
    "    sum_original_score = 0\n",
    "    mean_original_score = 0\n",
    "    feature_score = {}\n",
    "    feature_importance = {}\n",
    "    for _, tuple_input_pred_prob in all_imput_tensor_of_path.items() :\n",
    "        input_tensor = tuple_input_pred_prob[0]\n",
    "        with torch.no_grad():\n",
    "            output_original = model(input_tensor)\n",
    "            probs_original = torch.nn.functional.softmax(output_original, dim=1)\n",
    "            original_score = probs_original[0, pred_class].item()\n",
    "            sum_original_score += original_score\n",
    "    mean_original_score = sum_original_score / len(all_imput_tensor_of_path)\n",
    "\n",
    "    for feature_idx in range(num_features):\n",
    "        def zero_out_feature(module, input, output, feature_idx=feature_idx):\n",
    "            output[:, feature_idx, :, :] = 0  # Désactiver la feature\n",
    "            return output\n",
    "\n",
    "        hook = model.features[layer_idx].register_forward_hook(zero_out_feature)\n",
    "\n",
    "        sum_new_score = 0\n",
    "        mean_new_score = 0\n",
    "        for _, tuple_input_pred_prob in all_imput_tensor_of_path.items():\n",
    "            input_tensor = tuple_input_pred_prob[0]\n",
    "            with torch.no_grad():\n",
    "                output_disabled = model(input_tensor)\n",
    "                probs_disabled = torch.nn.functional.softmax(output_disabled, dim=1)\n",
    "                new_score = probs_disabled[0, pred_class].item()\n",
    "                sum_new_score += new_score\n",
    "        mean_new_score = sum_new_score / len(all_imput_tensor_of_path)\n",
    "        hook.remove()\n",
    "\n",
    "        feature_score[feature_idx] = mean_new_score\n",
    "\n",
    "        # Affichage de progression\n",
    "        importance = mean_original_score - mean_new_score\n",
    "        feature_importance[feature_idx] = importance\n",
    "        print(f\"Feature {feature_idx+1}/{num_features} - Importance: {importance:.4f}\")\n",
    "\n",
    "    sorted_importance = dict(sorted(feature_importance.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return sorted_importance, mean_original_score, feature_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_images(folder_path):\n",
    "    all_imput_tensor_of_path = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpeg\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            all_imput_tensor_of_path[filename] = input_tensor\n",
    "            #print(f\"Image {filename} chargée et transformée.\")\n",
    "    return all_imput_tensor_of_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def separate_well_bad_predicted(all_imput_tensor_of_path, expected_class):\n",
    "    all_wrong_predicted = {}\n",
    "    all_well_predicted = {}\n",
    "    for name, input_tensor in all_imput_tensor_of_path.items() :\n",
    "        with torch.no_grad():\n",
    "            output_original = model(input_tensor)\n",
    "            pred_class = torch.argmax(output_original, dim=1).item()\n",
    "            probs_original = torch.nn.functional.softmax(output_original, dim=1)\n",
    "            original_score = probs_original[0, pred_class].item()\n",
    "        if pred_class != expected_class :\n",
    "            all_wrong_predicted[name] = (input_tensor, pred_class, original_score)\n",
    "            continue\n",
    "        all_well_predicted[name] = (input_tensor, pred_class, original_score)\n",
    "    print(f\"Nombre d'images mal prédites : {len(all_wrong_predicted)}\")\n",
    "    return all_wrong_predicted, all_well_predicted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def positive_negative_features(importance_dict):\n",
    "    positiveFeatures = []\n",
    "    negativeFeatures = []\n",
    "\n",
    "    for feature, importance in importance_dict.items():\n",
    "        if importance >= 0:\n",
    "            positiveFeatures.append(feature)\n",
    "        elif importance < 0:\n",
    "            negativeFeatures.append(feature)\n",
    "\n",
    "    print(f\"Il y a {len(positiveFeatures)} features positives et {len(negativeFeatures)} features négatives.\")\n",
    "    return positiveFeatures, negativeFeatures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folder_path_toucan = r\"C:\\Annexe_D\\PER\\data\\train\\n01843383\" #toucan\n",
    "folder_path_hornbill = r\"C:\\Annexe_D\\PER\\data\\train\\n01829413\"#hornbill\n",
    "folder_path_panda = r\"C:\\Annexe_D\\PER\\data\\train\\n02510455\"#panda\n",
    "folder_path_elephant = r\"C:\\Annexe_D\\PER\\data\\train\\n02504013\"#elephant\n",
    "folder_path_ourangoutan = r\"C:\\Annexe_D\\PER\\data\\train\\n02480495\"#ourangoutan\n",
    "folder_path_goldfish = r\"C:\\Annexe_D\\PER\\data\\train\\n01443537\"#goldfish"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "expected_class_toucan = 96\n",
    "expected_class_hornbill = 93\n",
    "expected_class_panda = 388\n",
    "expected_class_elephant = 385\n",
    "expected_class_ourangoutan = 365\n",
    "expected_class_goldfish = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_folder_path = [folder_path_toucan, folder_path_hornbill, folder_path_panda, folder_path_elephant, folder_path_ourangoutan, folder_path_goldfish]\n",
    "list_expected_class = [expected_class_toucan, expected_class_hornbill, expected_class_panda, expected_class_elephant, expected_class_ourangoutan, expected_class_goldfish]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_all(list_folder_path, list_expected_class):\n",
    "    global_dict = {}\n",
    "    for folder_path, expected_class in zip(list_folder_path, list_expected_class):\n",
    "        all_imput_tensor_of_path = load_images(folder_path)\n",
    "        all_wrong_predicted, all_well_predicted = separate_well_bad_predicted(all_imput_tensor_of_path, expected_class)\n",
    "        importance_dict, mean_original_score, feature_score = compute_feature_importance_all_input_tensor(model, all_well_predicted, layer_idx=40, num_features=512, pred_class=expected_class)\n",
    "        global_dict[expected_class] = (importance_dict, mean_original_score, feature_score)\n",
    "    return global_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def create_json_from_data(data, output_filename):\n",
    "\n",
    "    # Créer un dictionnaire pour les données au format désiré\n",
    "    image_data = {}\n",
    "\n",
    "    for expected_class, info in data.items():\n",
    "        # Extraire les informations : classe, probabilité, et dictionnaire de features\n",
    "        importance_dict = info[0]\n",
    "        mean_original_score = info[1]\n",
    "        feature_score = info[2]\n",
    "\n",
    "        # Ajouter ces informations dans le dictionnaire final\n",
    "        image_data[expected_class] = {\n",
    "            'importance_dict': importance_dict,\n",
    "            'mean_original_score': mean_original_score,\n",
    "            'feature_score': feature_score\n",
    "        }\n",
    "\n",
    "    # Sauvegarder les données dans un fichier JSON\n",
    "    with open(output_filename, 'w') as json_file:\n",
    "        json.dump(image_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Le fichier JSON '{output_filename}' a été créé avec succès.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global_dict = run_all(list_folder_path, list_expected_class)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier JSON 'global_dict.json' a été créé avec succès.\n"
     ]
    }
   ],
   "source": [
    "create_json_from_data(global_dict, \"global_dict.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
